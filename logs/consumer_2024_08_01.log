2024-08-01 10:50:38,945 - __main__ - INFO - Spark connection created successfully!
2024-08-01 10:50:38,945 - root - INFO - Streaming is being started...
2024-08-01 10:50:40,842 - root - WARNING - kafka dataframe could not be created because: An error occurred while calling o43.load.
: java.lang.NoClassDefFoundError: scala/$less$colon$less
	at org.apache.spark.sql.kafka010.KafkaSourceProvider.org$apache$spark$sql$kafka010$KafkaSourceProvider$$validateStreamOptions(KafkaSourceProvider.scala:338)
	at org.apache.spark.sql.kafka010.KafkaSourceProvider.sourceSchema(KafkaSourceProvider.scala:71)
	at org.apache.spark.sql.execution.datasources.DataSource.sourceSchema(DataSource.scala:233)
	at org.apache.spark.sql.execution.datasources.DataSource.sourceInfo$lzycompute(DataSource.scala:118)
	at org.apache.spark.sql.execution.datasources.DataSource.sourceInfo(DataSource.scala:118)
	at org.apache.spark.sql.execution.streaming.StreamingRelation$.apply(StreamingRelation.scala:36)
	at org.apache.spark.sql.streaming.DataStreamReader.loadInternal(DataStreamReader.scala:169)
	at org.apache.spark.sql.streaming.DataStreamReader.load(DataStreamReader.scala:145)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.lang.ClassNotFoundException: scala.$less$colon$less
	at java.net.URLClassLoader.findClass(URLClassLoader.java:387)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	... 20 more

2024-08-01 10:50:40,843 - __main__ - ERROR - Error in streaming application
Traceback (most recent call last):
  File "/Users/naman/Desktop/Projects/Algo-IIFL/jobs/API_Consumer.py", line 111, in main
    tickerDf = read_kafka_topic('market_data_topic', schema).alias('market')
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'alias'
2024-08-01 10:50:40,849 - py4j.clientserver - INFO - Closing down clientserver connection
2024-08-01 10:53:53,944 - __main__ - INFO - Spark connection created successfully!
2024-08-01 10:53:53,945 - root - INFO - Streaming is being started...
2024-08-01 10:53:55,797 - root - WARNING - kafka dataframe could not be created because: An error occurred while calling o43.load.
: java.lang.NoClassDefFoundError: scala/$less$colon$less
	at org.apache.spark.sql.kafka010.KafkaSourceProvider.org$apache$spark$sql$kafka010$KafkaSourceProvider$$validateStreamOptions(KafkaSourceProvider.scala:338)
	at org.apache.spark.sql.kafka010.KafkaSourceProvider.sourceSchema(KafkaSourceProvider.scala:71)
	at org.apache.spark.sql.execution.datasources.DataSource.sourceSchema(DataSource.scala:233)
	at org.apache.spark.sql.execution.datasources.DataSource.sourceInfo$lzycompute(DataSource.scala:118)
	at org.apache.spark.sql.execution.datasources.DataSource.sourceInfo(DataSource.scala:118)
	at org.apache.spark.sql.execution.streaming.StreamingRelation$.apply(StreamingRelation.scala:36)
	at org.apache.spark.sql.streaming.DataStreamReader.loadInternal(DataStreamReader.scala:169)
	at org.apache.spark.sql.streaming.DataStreamReader.load(DataStreamReader.scala:145)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.lang.ClassNotFoundException: scala.$less$colon$less
	at java.net.URLClassLoader.findClass(URLClassLoader.java:387)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	... 20 more

2024-08-01 10:53:55,798 - __main__ - ERROR - Error in streaming application
Traceback (most recent call last):
  File "/Users/naman/Desktop/Projects/Algo-IIFL/jobs/API_Consumer.py", line 111, in main
    tickerDf = read_kafka_topic('market_data_topic', schema).alias('market')
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'alias'
2024-08-01 10:53:55,802 - py4j.clientserver - INFO - Closing down clientserver connection
2024-08-01 11:21:34,090 - __main__ - ERROR - Couldn't create the spark session due to exception An error occurred while calling o39.text.
: java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found
	at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2688)
	at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3431)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3466)
	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)
	at org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$checkAndGlobPathIfNecessary$1(DataSource.scala:724)
	at scala.collection.immutable.List.map(List.scala:293)
	at org.apache.spark.sql.execution.datasources.DataSource$.checkAndGlobPathIfNecessary(DataSource.scala:722)
	at org.apache.spark.sql.execution.datasources.DataSource.checkAndGlobPathIfNecessary(DataSource.scala:551)
	at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:404)
	at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)
	at org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)
	at scala.Option.getOrElse(Option.scala:189)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)
	at org.apache.spark.sql.DataFrameReader.text(DataFrameReader.scala:646)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found
	at org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2592)
	at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2686)
	... 29 more

2024-08-01 11:21:34,094 - root - INFO - Streaming is being started...
2024-08-01 11:21:34,301 - root - WARNING - kafka dataframe could not be created because: An error occurred while calling o48.load.
: java.lang.NoClassDefFoundError: scala/$less$colon$less
	at org.apache.spark.sql.kafka010.KafkaSourceProvider.org$apache$spark$sql$kafka010$KafkaSourceProvider$$validateStreamOptions(KafkaSourceProvider.scala:338)
	at org.apache.spark.sql.kafka010.KafkaSourceProvider.sourceSchema(KafkaSourceProvider.scala:71)
	at org.apache.spark.sql.execution.datasources.DataSource.sourceSchema(DataSource.scala:233)
	at org.apache.spark.sql.execution.datasources.DataSource.sourceInfo$lzycompute(DataSource.scala:118)
	at org.apache.spark.sql.execution.datasources.DataSource.sourceInfo(DataSource.scala:118)
	at org.apache.spark.sql.execution.streaming.StreamingRelation$.apply(StreamingRelation.scala:36)
	at org.apache.spark.sql.streaming.DataStreamReader.loadInternal(DataStreamReader.scala:169)
	at org.apache.spark.sql.streaming.DataStreamReader.load(DataStreamReader.scala:145)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.lang.ClassNotFoundException: scala.$less$colon$less
	at java.net.URLClassLoader.findClass(URLClassLoader.java:387)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	... 20 more

2024-08-01 11:21:34,302 - py4j.clientserver - INFO - Closing down clientserver connection
2024-08-01 11:23:09,338 - __main__ - ERROR - Couldn't create the spark session due to exception An error occurred while calling o39.text.
: java.io.IOException: From option fs.s3a.aws.credentials.provider java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.auth.IAMInstanceCredentialsProvider not found
	at org.apache.hadoop.fs.s3a.S3AUtils.loadAWSProviderClasses(S3AUtils.java:631)
	at org.apache.hadoop.fs.s3a.S3AUtils.createAWSCredentialProviderSet(S3AUtils.java:597)
	at org.apache.hadoop.fs.s3a.S3AFileSystem.initialize(S3AFileSystem.java:257)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469)
	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)
	at org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$checkAndGlobPathIfNecessary$1(DataSource.scala:724)
	at scala.collection.immutable.List.map(List.scala:293)
	at org.apache.spark.sql.execution.datasources.DataSource$.checkAndGlobPathIfNecessary(DataSource.scala:722)
	at org.apache.spark.sql.execution.datasources.DataSource.checkAndGlobPathIfNecessary(DataSource.scala:551)
	at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:404)
	at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)
	at org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)
	at scala.Option.getOrElse(Option.scala:189)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)
	at org.apache.spark.sql.DataFrameReader.text(DataFrameReader.scala:646)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.auth.IAMInstanceCredentialsProvider not found
	at org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2592)
	at org.apache.hadoop.conf.Configuration.getClasses(Configuration.java:2663)
	at org.apache.hadoop.fs.s3a.S3AUtils.loadAWSProviderClasses(S3AUtils.java:628)
	... 30 more

2024-08-01 11:23:09,340 - root - INFO - Streaming is being started...
2024-08-01 11:23:09,607 - root - WARNING - kafka dataframe could not be created because: An error occurred while calling o48.load.
: java.lang.NoClassDefFoundError: scala/$less$colon$less
	at org.apache.spark.sql.kafka010.KafkaSourceProvider.org$apache$spark$sql$kafka010$KafkaSourceProvider$$validateStreamOptions(KafkaSourceProvider.scala:338)
	at org.apache.spark.sql.kafka010.KafkaSourceProvider.sourceSchema(KafkaSourceProvider.scala:71)
	at org.apache.spark.sql.execution.datasources.DataSource.sourceSchema(DataSource.scala:233)
	at org.apache.spark.sql.execution.datasources.DataSource.sourceInfo$lzycompute(DataSource.scala:118)
	at org.apache.spark.sql.execution.datasources.DataSource.sourceInfo(DataSource.scala:118)
	at org.apache.spark.sql.execution.streaming.StreamingRelation$.apply(StreamingRelation.scala:36)
	at org.apache.spark.sql.streaming.DataStreamReader.loadInternal(DataStreamReader.scala:169)
	at org.apache.spark.sql.streaming.DataStreamReader.load(DataStreamReader.scala:145)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.lang.ClassNotFoundException: scala.$less$colon$less
	at java.net.URLClassLoader.findClass(URLClassLoader.java:387)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	... 20 more

2024-08-01 11:23:09,609 - py4j.clientserver - INFO - Closing down clientserver connection
2024-08-01 11:26:46,886 - __main__ - ERROR - Couldn't create the spark session due to exception An error occurred while calling o39.text.
: java.io.IOException: From option fs.s3a.aws.credentials.provider java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.auth.IAMInstanceCredentialsProvider not found
	at org.apache.hadoop.fs.s3a.S3AUtils.loadAWSProviderClasses(S3AUtils.java:631)
	at org.apache.hadoop.fs.s3a.S3AUtils.createAWSCredentialProviderSet(S3AUtils.java:597)
	at org.apache.hadoop.fs.s3a.S3AFileSystem.initialize(S3AFileSystem.java:257)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469)
	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)
	at org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$checkAndGlobPathIfNecessary$1(DataSource.scala:724)
	at scala.collection.immutable.List.map(List.scala:293)
	at org.apache.spark.sql.execution.datasources.DataSource$.checkAndGlobPathIfNecessary(DataSource.scala:722)
	at org.apache.spark.sql.execution.datasources.DataSource.checkAndGlobPathIfNecessary(DataSource.scala:551)
	at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:404)
	at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)
	at org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)
	at scala.Option.getOrElse(Option.scala:189)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)
	at org.apache.spark.sql.DataFrameReader.text(DataFrameReader.scala:646)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.auth.IAMInstanceCredentialsProvider not found
	at org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2592)
	at org.apache.hadoop.conf.Configuration.getClasses(Configuration.java:2663)
	at org.apache.hadoop.fs.s3a.S3AUtils.loadAWSProviderClasses(S3AUtils.java:628)
	... 30 more

2024-08-01 11:26:46,888 - root - INFO - Streaming is being started...
2024-08-01 11:26:47,124 - root - WARNING - kafka dataframe could not be created because: An error occurred while calling o48.load.
: java.lang.NoClassDefFoundError: scala/$less$colon$less
	at org.apache.spark.sql.kafka010.KafkaSourceProvider.org$apache$spark$sql$kafka010$KafkaSourceProvider$$validateStreamOptions(KafkaSourceProvider.scala:338)
	at org.apache.spark.sql.kafka010.KafkaSourceProvider.sourceSchema(KafkaSourceProvider.scala:71)
	at org.apache.spark.sql.execution.datasources.DataSource.sourceSchema(DataSource.scala:233)
	at org.apache.spark.sql.execution.datasources.DataSource.sourceInfo$lzycompute(DataSource.scala:118)
	at org.apache.spark.sql.execution.datasources.DataSource.sourceInfo(DataSource.scala:118)
	at org.apache.spark.sql.execution.streaming.StreamingRelation$.apply(StreamingRelation.scala:36)
	at org.apache.spark.sql.streaming.DataStreamReader.loadInternal(DataStreamReader.scala:169)
	at org.apache.spark.sql.streaming.DataStreamReader.load(DataStreamReader.scala:145)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.lang.ClassNotFoundException: scala.$less$colon$less
	at java.net.URLClassLoader.findClass(URLClassLoader.java:387)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	... 20 more

2024-08-01 11:26:47,127 - py4j.clientserver - INFO - Closing down clientserver connection
2024-08-01 11:30:48,713 - __main__ - ERROR - Couldn't create the spark session due to exception An error occurred while calling o39.text.
: java.io.IOException: From option fs.s3a.aws.credentials.provider java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.auth.IAMInstanceCredentialsProvider not found
	at org.apache.hadoop.fs.s3a.S3AUtils.loadAWSProviderClasses(S3AUtils.java:631)
	at org.apache.hadoop.fs.s3a.S3AUtils.createAWSCredentialProviderSet(S3AUtils.java:597)
	at org.apache.hadoop.fs.s3a.S3AFileSystem.initialize(S3AFileSystem.java:257)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469)
	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)
	at org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$checkAndGlobPathIfNecessary$1(DataSource.scala:724)
	at scala.collection.immutable.List.map(List.scala:293)
	at org.apache.spark.sql.execution.datasources.DataSource$.checkAndGlobPathIfNecessary(DataSource.scala:722)
	at org.apache.spark.sql.execution.datasources.DataSource.checkAndGlobPathIfNecessary(DataSource.scala:551)
	at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:404)
	at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)
	at org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)
	at scala.Option.getOrElse(Option.scala:189)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)
	at org.apache.spark.sql.DataFrameReader.text(DataFrameReader.scala:646)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.auth.IAMInstanceCredentialsProvider not found
	at org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2592)
	at org.apache.hadoop.conf.Configuration.getClasses(Configuration.java:2663)
	at org.apache.hadoop.fs.s3a.S3AUtils.loadAWSProviderClasses(S3AUtils.java:628)
	... 30 more

2024-08-01 11:30:48,714 - root - INFO - Streaming is being started...
2024-08-01 11:30:48,965 - root - WARNING - kafka dataframe could not be created because: An error occurred while calling o48.load.
: java.lang.NoClassDefFoundError: scala/$less$colon$less
	at org.apache.spark.sql.kafka010.KafkaSourceProvider.org$apache$spark$sql$kafka010$KafkaSourceProvider$$validateStreamOptions(KafkaSourceProvider.scala:338)
	at org.apache.spark.sql.kafka010.KafkaSourceProvider.sourceSchema(KafkaSourceProvider.scala:71)
	at org.apache.spark.sql.execution.datasources.DataSource.sourceSchema(DataSource.scala:233)
	at org.apache.spark.sql.execution.datasources.DataSource.sourceInfo$lzycompute(DataSource.scala:118)
	at org.apache.spark.sql.execution.datasources.DataSource.sourceInfo(DataSource.scala:118)
	at org.apache.spark.sql.execution.streaming.StreamingRelation$.apply(StreamingRelation.scala:36)
	at org.apache.spark.sql.streaming.DataStreamReader.loadInternal(DataStreamReader.scala:169)
	at org.apache.spark.sql.streaming.DataStreamReader.load(DataStreamReader.scala:145)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.lang.ClassNotFoundException: scala.$less$colon$less
	at java.net.URLClassLoader.findClass(URLClassLoader.java:387)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	... 20 more

2024-08-01 11:30:48,967 - py4j.clientserver - INFO - Closing down clientserver connection
2024-08-01 11:39:11,663 - __main__ - INFO - Spark connection created successfully!
2024-08-01 11:39:11,664 - root - INFO - Streaming is being started...
2024-08-01 11:39:11,858 - root - WARNING - kafka dataframe could not be created because: An error occurred while calling o47.load.
: java.lang.NoClassDefFoundError: scala/$less$colon$less
	at org.apache.spark.sql.kafka010.KafkaSourceProvider.org$apache$spark$sql$kafka010$KafkaSourceProvider$$validateStreamOptions(KafkaSourceProvider.scala:338)
	at org.apache.spark.sql.kafka010.KafkaSourceProvider.sourceSchema(KafkaSourceProvider.scala:71)
	at org.apache.spark.sql.execution.datasources.DataSource.sourceSchema(DataSource.scala:233)
	at org.apache.spark.sql.execution.datasources.DataSource.sourceInfo$lzycompute(DataSource.scala:118)
	at org.apache.spark.sql.execution.datasources.DataSource.sourceInfo(DataSource.scala:118)
	at org.apache.spark.sql.execution.streaming.StreamingRelation$.apply(StreamingRelation.scala:36)
	at org.apache.spark.sql.streaming.DataStreamReader.loadInternal(DataStreamReader.scala:169)
	at org.apache.spark.sql.streaming.DataStreamReader.load(DataStreamReader.scala:145)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.lang.ClassNotFoundException: scala.$less$colon$less
	at java.net.URLClassLoader.findClass(URLClassLoader.java:387)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	... 20 more

2024-08-01 11:39:11,861 - py4j.clientserver - INFO - Closing down clientserver connection
2024-08-01 11:40:28,236 - __main__ - INFO - Spark connection created successfully!
2024-08-01 11:40:28,238 - root - INFO - Streaming is being started...
2024-08-01 11:40:28,423 - root - WARNING - kafka dataframe could not be created because: An error occurred while calling o47.load.
: java.lang.NoClassDefFoundError: scala/$less$colon$less
	at org.apache.spark.sql.kafka010.KafkaSourceProvider.org$apache$spark$sql$kafka010$KafkaSourceProvider$$validateStreamOptions(KafkaSourceProvider.scala:338)
	at org.apache.spark.sql.kafka010.KafkaSourceProvider.sourceSchema(KafkaSourceProvider.scala:71)
	at org.apache.spark.sql.execution.datasources.DataSource.sourceSchema(DataSource.scala:233)
	at org.apache.spark.sql.execution.datasources.DataSource.sourceInfo$lzycompute(DataSource.scala:118)
	at org.apache.spark.sql.execution.datasources.DataSource.sourceInfo(DataSource.scala:118)
	at org.apache.spark.sql.execution.streaming.StreamingRelation$.apply(StreamingRelation.scala:36)
	at org.apache.spark.sql.streaming.DataStreamReader.loadInternal(DataStreamReader.scala:169)
	at org.apache.spark.sql.streaming.DataStreamReader.load(DataStreamReader.scala:145)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.lang.ClassNotFoundException: scala.$less$colon$less
	at java.net.URLClassLoader.findClass(URLClassLoader.java:387)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	... 20 more

2024-08-01 11:40:28,425 - py4j.clientserver - INFO - Closing down clientserver connection
2024-08-01 11:43:55,829 - __main__ - INFO - Spark connection created successfully!
2024-08-01 11:43:55,830 - root - INFO - Streaming is being started...
2024-08-01 11:43:57,987 - root - WARNING - kafka dataframe could not be created because: An error occurred while calling o42.load.
: java.lang.NoClassDefFoundError: scala/$less$colon$less
	at org.apache.spark.sql.kafka010.KafkaSourceProvider.org$apache$spark$sql$kafka010$KafkaSourceProvider$$validateStreamOptions(KafkaSourceProvider.scala:338)
	at org.apache.spark.sql.kafka010.KafkaSourceProvider.sourceSchema(KafkaSourceProvider.scala:71)
	at org.apache.spark.sql.execution.datasources.DataSource.sourceSchema(DataSource.scala:233)
	at org.apache.spark.sql.execution.datasources.DataSource.sourceInfo$lzycompute(DataSource.scala:118)
	at org.apache.spark.sql.execution.datasources.DataSource.sourceInfo(DataSource.scala:118)
	at org.apache.spark.sql.execution.streaming.StreamingRelation$.apply(StreamingRelation.scala:36)
	at org.apache.spark.sql.streaming.DataStreamReader.loadInternal(DataStreamReader.scala:169)
	at org.apache.spark.sql.streaming.DataStreamReader.load(DataStreamReader.scala:145)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.lang.ClassNotFoundException: scala.$less$colon$less
	at java.net.URLClassLoader.findClass(URLClassLoader.java:387)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	... 20 more

2024-08-01 11:43:57,990 - py4j.clientserver - INFO - Closing down clientserver connection
2024-08-01 11:50:58,482 - __main__ - INFO - Spark connection created successfully!
2024-08-01 11:50:58,483 - root - INFO - Streaming is being started...
2024-08-01 11:51:02,920 - root - INFO - kafka dataframe created successfully
2024-08-01 11:51:03,128 - py4j.clientserver - INFO - Closing down clientserver connection
2024-08-01 11:52:30,004 - __main__ - INFO - Spark connection created successfully!
2024-08-01 11:52:30,005 - root - INFO - Streaming is being started...
2024-08-01 11:52:37,847 - root - WARNING - kafka dataframe could not be created because: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `timestamp` cannot be resolved. Did you mean one of the following? [`ai`, `ap`, `ltp`, `ltq`, `ltt`].;
'EventTimeWatermark 'timestamp, 5 minutes
+- Project [data#23.t AS t#25, data#23.ltp AS ltp#26, data#23.ltq AS ltq#27L, data#23.tb AS tb#28L, data#23.ts AS ts#29L, data#23.v AS v#30L, data#23.ap AS ap#31, data#23.ltt AS ltt#32, data#23.lut AS lut#33, data#23.pc AS pc#34, data#23.o AS o#35, data#23.h AS h#36, data#23.l AS l#37, data#23.c AS c#38, data#23.vp AS vp#39, data#23.ai AS ai#40, data#23.bi AS bi#41]
   +- Project [from_json(StructField(t,StringType,false), StructField(ltp,DoubleType,false), StructField(ltq,LongType,false), StructField(tb,LongType,false), StructField(ts,LongType,false), StructField(v,LongType,false), StructField(ap,DoubleType,false), StructField(ltt,TimestampType,false), StructField(lut,TimestampType,false), StructField(pc,DoubleType,false), StructField(o,DoubleType,false), StructField(h,DoubleType,false), StructField(l,DoubleType,false), StructField(c,DoubleType,false), StructField(vp,DoubleType,false), StructField(ai,StringType,false), StructField(bi,StringType,false), value#21, Some(America/Chicago)) AS data#23]
      +- Project [cast(value#8 as string) AS value#21]
         +- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@5dc7ab0, kafka, org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@62e64e6d, [startingOffsets=earliest, kafka.bootstrap.servers=broker:29092, subscribe=market_data_topic], [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@46596f8a,kafka,List(),None,List(),None,Map(kafka.bootstrap.servers -> broker:29092, subscribe -> market_data_topic, startingOffsets -> earliest),None), kafka, [key#0, value#1, topic#2, partition#3, offset#4L, timestamp#5, timestampType#6]

2024-08-01 11:52:37,848 - __main__ - INFO - Starting stream writer with checkpoint folder: s3a://algo-iifl/checkpoints/tick_data and output path: s3a://algo-iifl/data
2024-08-01 11:52:37,849 - __main__ - ERROR - Error starting stream writer with checkpoint folder: s3a://algo-iifl/checkpoints/tick_data and output path: s3a://algo-iifl/data
Traceback (most recent call last):
  File "/Users/naman/Desktop/Projects/Algo-IIFL/jobs/test.py", line 92, in streamWriter
    return (input.writeStream\
            ^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'writeStream'
2024-08-01 11:52:37,854 - __main__ - ERROR - Error in streaming application
Traceback (most recent call last):
  File "/Users/naman/Desktop/Projects/Algo-IIFL/jobs/test.py", line 105, in main
    streaming_query = streamWriter(tickerDf, 's3a://algo-iifl/checkpoints/tick_data', 's3a://algo-iifl/data')
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/naman/Desktop/Projects/Algo-IIFL/jobs/test.py", line 92, in streamWriter
    return (input.writeStream\
            ^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'writeStream'
2024-08-01 11:52:37,855 - py4j.clientserver - INFO - Closing down clientserver connection
2024-08-01 11:53:17,473 - __main__ - INFO - Spark connection created successfully!
2024-08-01 11:53:17,474 - root - INFO - Streaming is being started...
2024-08-01 11:53:26,975 - root - WARNING - kafka dataframe could not be created because: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `timestamp` cannot be resolved. Did you mean one of the following? [`ai`, `ap`, `ltp`, `ltq`, `ltt`].;
'EventTimeWatermark 'timestamp, 5 minutes
+- Project [data#23.t AS t#25, data#23.ltp AS ltp#26, data#23.ltq AS ltq#27L, data#23.tb AS tb#28L, data#23.ts AS ts#29L, data#23.v AS v#30L, data#23.ap AS ap#31, data#23.ltt AS ltt#32, data#23.lut AS lut#33, data#23.pc AS pc#34, data#23.o AS o#35, data#23.h AS h#36, data#23.l AS l#37, data#23.c AS c#38, data#23.vp AS vp#39, data#23.ai AS ai#40, data#23.bi AS bi#41]
   +- Project [from_json(StructField(t,StringType,false), StructField(ltp,DoubleType,false), StructField(ltq,LongType,false), StructField(tb,LongType,false), StructField(ts,LongType,false), StructField(v,LongType,false), StructField(ap,DoubleType,false), StructField(ltt,TimestampType,false), StructField(lut,TimestampType,false), StructField(pc,DoubleType,false), StructField(o,DoubleType,false), StructField(h,DoubleType,false), StructField(l,DoubleType,false), StructField(c,DoubleType,false), StructField(vp,DoubleType,false), StructField(ai,StringType,false), StructField(bi,StringType,false), value#21, Some(America/Chicago)) AS data#23]
      +- Project [cast(value#8 as string) AS value#21]
         +- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@44074b78, kafka, org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@7f730c0b, [startingOffsets=earliest, kafka.bootstrap.servers=broker:29092, subscribe=market_data_topic], [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@4a9abb59,kafka,List(),None,List(),None,Map(kafka.bootstrap.servers -> broker:29092, subscribe -> market_data_topic, startingOffsets -> earliest),None), kafka, [key#0, value#1, topic#2, partition#3, offset#4L, timestamp#5, timestampType#6]

2024-08-01 11:53:26,976 - __main__ - INFO - Starting stream writer with checkpoint folder: s3a://algo-iifl/checkpoints/tick_data and output path: s3a://algo-iifl/data
2024-08-01 11:53:26,977 - __main__ - ERROR - Error starting stream writer with checkpoint folder: s3a://algo-iifl/checkpoints/tick_data and output path: s3a://algo-iifl/data
Traceback (most recent call last):
  File "/Users/naman/Desktop/Projects/Algo-IIFL/jobs/test.py", line 92, in streamWriter
    return (input.writeStream\
            ^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'writeStream'
2024-08-01 11:53:26,982 - __main__ - ERROR - Error in streaming application
Traceback (most recent call last):
  File "/Users/naman/Desktop/Projects/Algo-IIFL/jobs/test.py", line 105, in main
    streaming_query = streamWriter(tickerDf, 's3a://algo-iifl/checkpoints/tick_data', 's3a://algo-iifl/data')
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/naman/Desktop/Projects/Algo-IIFL/jobs/test.py", line 92, in streamWriter
    return (input.writeStream\
            ^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'writeStream'
2024-08-01 11:53:26,983 - py4j.clientserver - INFO - Closing down clientserver connection
2024-08-01 11:54:59,936 - __main__ - INFO - Spark connection created successfully!
2024-08-01 11:54:59,937 - root - INFO - Streaming is being started...
2024-08-01 11:55:07,639 - root - WARNING - kafka dataframe could not be created because: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `timestamp` cannot be resolved. Did you mean one of the following? [`ai`, `ap`, `ltp`, `ltq`, `ltt`].;
'EventTimeWatermark 'timestamp, 5 minutes
+- Project [data#23.t AS t#25, data#23.ltp AS ltp#26, data#23.ltq AS ltq#27L, data#23.tb AS tb#28L, data#23.ts AS ts#29L, data#23.v AS v#30L, data#23.ap AS ap#31, data#23.ltt AS ltt#32L, data#23.lut AS lut#33L, data#23.pc AS pc#34, data#23.o AS o#35, data#23.h AS h#36, data#23.l AS l#37, data#23.c AS c#38, data#23.vp AS vp#39, data#23.ai AS ai#40, data#23.bi AS bi#41]
   +- Project [from_json(StructField(t,StringType,false), StructField(ltp,DoubleType,false), StructField(ltq,LongType,false), StructField(tb,LongType,false), StructField(ts,LongType,false), StructField(v,LongType,false), StructField(ap,DoubleType,false), StructField(ltt,LongType,false), StructField(lut,LongType,false), StructField(pc,DoubleType,false), StructField(o,DoubleType,false), StructField(h,DoubleType,false), StructField(l,DoubleType,false), StructField(c,DoubleType,false), StructField(vp,DoubleType,false), StructField(ai,StringType,false), StructField(bi,StringType,false), value#21, Some(America/Chicago)) AS data#23]
      +- Project [cast(value#8 as string) AS value#21]
         +- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@5b4827b6, kafka, org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@6a18e28b, [startingOffsets=earliest, kafka.bootstrap.servers=broker:29092, subscribe=market_data_topic], [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@1833147a,kafka,List(),None,List(),None,Map(kafka.bootstrap.servers -> broker:29092, subscribe -> market_data_topic, startingOffsets -> earliest),None), kafka, [key#0, value#1, topic#2, partition#3, offset#4L, timestamp#5, timestampType#6]

2024-08-01 11:55:07,640 - __main__ - INFO - Starting stream writer with checkpoint folder: s3a://algo-iifl/checkpoints/tick_data and output path: s3a://algo-iifl/data
2024-08-01 11:55:07,640 - __main__ - ERROR - Error starting stream writer with checkpoint folder: s3a://algo-iifl/checkpoints/tick_data and output path: s3a://algo-iifl/data
Traceback (most recent call last):
  File "/Users/naman/Desktop/Projects/Algo-IIFL/jobs/test.py", line 92, in streamWriter
    return (input.writeStream\
            ^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'writeStream'
2024-08-01 11:55:07,644 - __main__ - ERROR - Error in streaming application
Traceback (most recent call last):
  File "/Users/naman/Desktop/Projects/Algo-IIFL/jobs/test.py", line 105, in main
    streaming_query = streamWriter(tickerDf, 's3a://algo-iifl/checkpoints/tick_data', 's3a://algo-iifl/data')
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/naman/Desktop/Projects/Algo-IIFL/jobs/test.py", line 92, in streamWriter
    return (input.writeStream\
            ^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'writeStream'
2024-08-01 11:55:07,646 - py4j.clientserver - INFO - Closing down clientserver connection
2024-08-01 11:57:20,252 - __main__ - INFO - Spark connection created successfully!
2024-08-01 11:57:20,253 - root - INFO - Streaming is being started...
2024-08-01 11:57:28,762 - root - WARNING - kafka dataframe could not be created because: Queries with streaming sources must be executed with writeStream.start();
kafka
2024-08-01 11:57:28,763 - __main__ - INFO - Starting stream writer with checkpoint folder: s3a://algo-iifl/checkpoints/tick_data and output path: s3a://algo-iifl/data
2024-08-01 11:57:28,763 - __main__ - ERROR - Error starting stream writer with checkpoint folder: s3a://algo-iifl/checkpoints/tick_data and output path: s3a://algo-iifl/data
Traceback (most recent call last):
  File "/Users/naman/Desktop/Projects/Algo-IIFL/jobs/test.py", line 95, in streamWriter
    return (input.writeStream\
            ^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'writeStream'
2024-08-01 11:57:28,764 - __main__ - ERROR - Error in streaming application
Traceback (most recent call last):
  File "/Users/naman/Desktop/Projects/Algo-IIFL/jobs/test.py", line 108, in main
    streaming_query = streamWriter(tickerDf, 's3a://algo-iifl/checkpoints/tick_data', 's3a://algo-iifl/data')
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/naman/Desktop/Projects/Algo-IIFL/jobs/test.py", line 95, in streamWriter
    return (input.writeStream\
            ^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'writeStream'
2024-08-01 11:57:28,766 - py4j.clientserver - INFO - Closing down clientserver connection
2024-08-01 12:02:48,623 - __main__ - INFO - Spark connection created successfully!
2024-08-01 12:02:48,624 - root - INFO - Streaming is being started...
2024-08-01 12:02:58,533 - root - WARNING - kafka dataframe could not be created because: Queries with streaming sources must be executed with writeStream.start();
kafka
2024-08-01 12:02:58,534 - __main__ - INFO - Starting stream writer with checkpoint folder: s3a://algo-iifl/checkpoints/tick_data and output path: s3a://algo-iifl/data
2024-08-01 12:02:58,534 - __main__ - ERROR - Error starting stream writer with checkpoint folder: s3a://algo-iifl/checkpoints/tick_data and output path: s3a://algo-iifl/data
Traceback (most recent call last):
  File "/Users/naman/Desktop/Projects/Algo-IIFL/jobs/test.py", line 101, in streamWriter
    return (input.writeStream\
            ^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'writeStream'
2024-08-01 12:02:58,540 - __main__ - ERROR - Error in streaming application
Traceback (most recent call last):
  File "/Users/naman/Desktop/Projects/Algo-IIFL/jobs/test.py", line 114, in main
    streaming_query = streamWriter(tickerDf, 's3a://algo-iifl/checkpoints/tick_data', 's3a://algo-iifl/data')
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/naman/Desktop/Projects/Algo-IIFL/jobs/test.py", line 101, in streamWriter
    return (input.writeStream\
            ^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'writeStream'
2024-08-01 12:02:58,542 - py4j.clientserver - INFO - Closing down clientserver connection
2024-08-01 12:08:17,207 - __main__ - INFO - Spark connection created successfully!
2024-08-01 12:08:17,208 - root - INFO - Streaming is being started...
2024-08-01 12:08:25,811 - root - WARNING - kafka dataframe could not be created because: Queries with streaming sources must be executed with writeStream.start();
kafka
2024-08-01 12:08:25,813 - __main__ - INFO - Starting stream writer with checkpoint folder: s3a://algo-iifl/checkpoints/tick_data and output path: s3a://algo-iifl/data
2024-08-01 12:08:25,813 - __main__ - ERROR - 'NoneType' object has no attribute 'writeStream': Error starting stream writer with checkpoint folder: s3a://algo-iifl/checkpoints/tick_data and output path: s3a://algo-iifl/data
Traceback (most recent call last):
  File "/Users/naman/Desktop/Projects/Algo-IIFL/jobs/test.py", line 101, in streamWriter
    .option('checkpointLocation', checkpointFolder)\
        ^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'writeStream'
2024-08-01 12:08:25,818 - __main__ - ERROR - Error in streaming application
Traceback (most recent call last):
  File "/Users/naman/Desktop/Projects/Algo-IIFL/jobs/test.py", line 114, in main
    logger.error("Error in streaming application", exc_info=True)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/naman/Desktop/Projects/Algo-IIFL/jobs/test.py", line 101, in streamWriter
    .option('checkpointLocation', checkpointFolder)\
        ^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'writeStream'
2024-08-01 12:08:25,821 - py4j.clientserver - INFO - Closing down clientserver connection
2024-08-01 12:09:48,539 - __main__ - INFO - Spark connection created successfully!
2024-08-01 12:09:48,539 - root - INFO - Streaming is being started...
2024-08-01 12:09:57,516 - root - WARNING - kafka dataframe could not be created because: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `timestamp` cannot be resolved. Did you mean one of the following? [`t`, `145`, `87`].;
'EventTimeWatermark 'timestamp, 5 minutes
+- Project [data#23.t AS t#25, data#23.87 AS 87#26, data#23.145 AS 145#27]
   +- Project [from_json(StructField(t,StringType,false), StructField(87,DoubleType,false), StructField(145,DoubleType,false), value#21, Some(America/Chicago)) AS data#23]
      +- Project [cast(value#8 as string) AS value#21]
         +- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@1a313941, kafka, org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@20248e16, [startingOffsets=earliest, kafka.bootstrap.servers=broker:29092, subscribe=market_data_topic], [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@71d4acbe,kafka,List(),None,List(),None,Map(kafka.bootstrap.servers -> broker:29092, subscribe -> market_data_topic, startingOffsets -> earliest),None), kafka, [key#0, value#1, topic#2, partition#3, offset#4L, timestamp#5, timestampType#6]

2024-08-01 12:09:57,517 - __main__ - ERROR - Ticker dataframe is None. Exiting application.
2024-08-01 12:09:57,518 - py4j.clientserver - INFO - Closing down clientserver connection
2024-08-01 12:11:06,388 - __main__ - INFO - Spark connection created successfully!
2024-08-01 12:11:06,389 - root - INFO - Streaming is being started...
2024-08-01 12:11:12,449 - root - INFO - kafka dataframe created successfully
2024-08-01 12:11:12,450 - __main__ - INFO - Starting stream writer with checkpoint folder: s3a://algo-iifl/checkpoints/tick_data and output path: s3a://algo-iifl/data
2024-08-01 12:11:38,412 - __main__ - ERROR - Error in streaming application
Traceback (most recent call last):
  File "/Users/naman/Desktop/Projects/Algo-IIFL/jobs/test.py", line 115, in main
    streaming_query.awaitTermination()
  File "/Users/naman/Desktop/Projects/Algo-IIFL/algo_venv/lib/python3.11/site-packages/pyspark/sql/streaming/query.py", line 221, in awaitTermination
    return self._jsq.awaitTermination()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/naman/Desktop/Projects/Algo-IIFL/algo_venv/lib/python3.11/site-packages/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
                   ^^^^^^^^^^^^^^^^^
  File "/Users/naman/Desktop/Projects/Algo-IIFL/algo_venv/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py", line 185, in deco
    raise converted from None
pyspark.errors.exceptions.captured.StreamingQueryException: [STREAM_FAILED] Query [id = 82b1576f-4626-4b12-bd1f-d662675c7c7b, runId = 2ac65f41-0872-4254-826e-76b518e9875a] terminated with exception: Failed to create new KafkaAdminClient
2024-08-01 12:11:38,447 - py4j.clientserver - INFO - Closing down clientserver connection
